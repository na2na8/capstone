{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pyjosa\n",
    "import random\n",
    "\n",
    "item_list = ['우유', '치즈', '사탕', '아이스크림', '과자', '김치']\n",
    "\n",
    "# 어절 태깅\n",
    "def tagging_words(product) :\n",
    "    words_tagging = []\n",
    "    splitted= product.split(\" \")\n",
    "    \n",
    "    len_splitted = len(splitted)-1\n",
    "    # splitted 사이사이에 \" \" 채워주기\n",
    "    while len_splitted > 0 :\n",
    "        splitted.insert(len_splitted, \" \")\n",
    "        len_splitted -= 1\n",
    "        \n",
    "    len_splitted = len(splitted)-1\n",
    "    # 태깅. 완벽하지 않아 수동으로 체크해 주어야 함. \n",
    "    # (ex : 치즈 케이크인경우 치즈를 품목으로 생각하기 때문에 이를 바꾸어 주어야 함)\n",
    "    for item in splitted :\n",
    "        if item in item_list :\n",
    "            words_tagging.append('PRDG_B')\n",
    "        else :\n",
    "            # 품목명이 아닌 경우 모두 PRD_I를 태깅해 줌.\n",
    "            words_tagging.append('PRD_I')\n",
    "    # 품목명이 있을 경우 ' '의 위치에 '-'를 붙이는 경우\n",
    "    try :\n",
    "        # 품목명 위치 찾기\n",
    "        where_prdg = words_tagging.index('PRDG_B')\n",
    "        if where_prdg != 0 and splitted[where_prdg-1] == ' ' :\n",
    "            words_tagging[where_prdg -1] = '-'\n",
    "        if (where_prdg != len_splitted) and splitted[where_prdg+1] == ' ':\n",
    "            words_tagging[where_prdg +1] = '-'\n",
    "    except :\n",
    "        pass\n",
    "    \n",
    "    try :\n",
    "        # 처음 PRD_I를 찾은 곳에 PRD_B로 바꿔주기\n",
    "        find_prd_b = words_tagging.index('PRD_I')\n",
    "        words_tagging[find_prd_b] = 'PRD_B'\n",
    "    except :\n",
    "        pass\n",
    "    return splitted, words_tagging\n",
    "    \n",
    "\n",
    "# 음절 태깅\n",
    "def tagging_syllables(product, words, words_tagging) :\n",
    "    product_length = len(product)\n",
    "    syllables = []\n",
    "    syl_tagging = []\n",
    "    # 음절단위로 product 쪼개기\n",
    "    for i in range(0, product_length) :\n",
    "        syllables.append(product[i])\n",
    "        \n",
    "    for word_idx in range(0, len(words)) :\n",
    "        words_length = len(words[word_idx])\n",
    "        # 어절 태깅이 PRD_B일 때\n",
    "        if words_tagging[word_idx] == 'PRD_B' :\n",
    "            for j in range(0,words_length) :\n",
    "                 # PRD_B 단어의 첫 음절만 PRD_B\n",
    "                if j == 0 :\n",
    "                    syl_tagging.append('PRD_B')\n",
    "                else :\n",
    "                    syl_tagging.append('PRD_I')\n",
    "        # 어절 태깅이 PRD_I일 때\n",
    "        elif words_tagging[word_idx] == 'PRD_I' :\n",
    "            for j in range(0, words_length) :\n",
    "                syl_tagging.append('PRD_I')\n",
    "        # 어절 태깅이 PRDG_B일 때\n",
    "        elif words_tagging[word_idx] == 'PRDG_B' :\n",
    "            for j in range(0,words_length) :\n",
    "                if j == 0 :\n",
    "                    syl_tagging.append('PRDG_B')\n",
    "                else :\n",
    "                    syl_tagging.append('PRDG_I')\n",
    "        else :\n",
    "            for j in range(0, words_length) :\n",
    "                syl_tagging.append('-')\n",
    "        \n",
    "    return syllables, syl_tagging\n",
    "\n",
    "\n",
    "def str_to_list(words):\n",
    "    words=words.replace('\\'','')\n",
    "    words=words.replace('[','')\n",
    "    words=words.replace(']','')\n",
    "    words=words.split(',')\n",
    "    for i in range(len(words)) :\n",
    "        words[i] = words[i].strip()\n",
    "        if len(words[i]) == 0 :\n",
    "            words[i] = ' '\n",
    "    return words\n",
    "\n",
    "\n",
    "# filename : 태깅 된 csv\n",
    "def choose_plural(filename, length) :\n",
    "    data = pd.read_csv(filename)\n",
    "    # 복수 2개를 랜덤 두 개 선택\n",
    "    num1 = random.randrange(0, length)\n",
    "    num2 = random.randrange(0, length)\n",
    "    # 중복 제거\n",
    "    while num2 == num1 :\n",
    "        num2 = random.randrange(0,length)\n",
    "    # 상품 이름\n",
    "    name1 = str(data.loc[num1, 'product'])\n",
    "    name2 = str(data.loc[num2, 'product'])\n",
    "    \n",
    "    # 상품 어절\n",
    "    name1_words = str_to_list(data.loc[num1, 'words'])\n",
    "    name2_words = str_to_list(data.loc[num2, 'words'])\n",
    "    \n",
    "    # 상품 어절 태깅\n",
    "    name1_words_tagging = str_to_list(data.loc[num1, 'words_tagging'])\n",
    "    name2_words_tagging = str_to_list(data.loc[num2, 'words_tagging'])\n",
    "    \n",
    "    # 상품 음절\n",
    "    name1_syllables = str_to_list(data.loc[num1, 'syllables'])\n",
    "    name2_syllables = str_to_list(data.loc[num2, 'syllables'])\n",
    "    \n",
    "    # 상품 음절 태깅\n",
    "    name1_syllables_tagging = str_to_list(data.loc[num1, 'syllables_tagging'])\n",
    "    name2_syllables_tagging = str_to_list(data.loc[num2, 'syllables_tagging'])\n",
    "    \n",
    "    plural = pyjosa.replace_josa(name1 + \"(와)과 \" + name2)\n",
    "    \n",
    "    words = []\n",
    "    words_tagging = []\n",
    "    syllables = []\n",
    "    syllables_tagging = []\n",
    "    \n",
    "    len_name1 = len(name1)\n",
    "    # 조사(와, 과) 위치\n",
    "    josa = plural[len_name1]\n",
    "    josa2 = ''\n",
    "    if josa == '과' :\n",
    "        josa2 = '이랑'\n",
    "    elif josa == '와' :\n",
    "        josa2 = '랑'\n",
    "    \n",
    "    # ------------------------------------------------------------------------------------------------------------ #\n",
    "    # name 1\n",
    "    # 어절\n",
    "    for i in range(0, len(name1_words)) :\n",
    "        words.append(name1_words[i])\n",
    "    # 태그된 어절\n",
    "    for i in range(0, len(name1_words_tagging)) :\n",
    "        words_tagging.append(name1_words_tagging[i])\n",
    "    \n",
    "    # 음절\n",
    "    for i in range(0, len(name1_syllables)) :\n",
    "        syllables.append(name1_syllables[i])\n",
    "    # 태그된 음절\n",
    "    for i in range(0, len(name1_syllables_tagging)) :\n",
    "        syllables_tagging.append(name1_syllables_tagging[i])\n",
    "    \n",
    "    # ------------------------------------------------------------------------------------------------------------ #\n",
    "    # ------------- case 1 조사 : 와/과, case 2 조사 : 랑/이랑, case 3 조사 : 조사없이 그냥 붙을 때 -------------- #\n",
    "    case = random.randrange(1,4)\n",
    "    \n",
    "    # 와/과\n",
    "    if case == 1 :\n",
    "        words.append(josa)\n",
    "        words.append(' ')    \n",
    "        # 조사 어절 태깅\n",
    "        words_tagging.append('-')\n",
    "        # 띄어쓰기 어절 태깅\n",
    "        words_tagging.append('-')\n",
    "        # 조사 음절 태깅\n",
    "        syllables.append(josa)\n",
    "        syllables.append(' ')\n",
    "        # 띄어쓰기 음절 태깅\n",
    "        syllables_tagging.append('-')\n",
    "    # 이랑/랑\n",
    "    elif case == 2 :\n",
    "        words.append(josa2)\n",
    "        words.append(' ')\n",
    "        # 조사 어절 태깅\n",
    "        words_tagging.append('-')\n",
    "        # 띄어쓰기 어절 태깅\n",
    "        words_tagging.append('-')\n",
    "        len_josa2 = len(josa2)\n",
    "        # 조사 음절 태깅\n",
    "        for i in range(0, len_josa2) :\n",
    "            syllables.append(josa2[i])\n",
    "        syllables.append(' ')\n",
    "        # 띄어쓰기 음절 태깅\n",
    "        for i in range(0, len_josa2) :\n",
    "            syllables_tagging.append('-')\n",
    "        syllables_tagging.append('-')\n",
    "    # 조사 X\n",
    "    else :\n",
    "        # 띄어쓰기\n",
    "        words.append(' ')\n",
    "        # 띄어쓰기 태깅\n",
    "        words_tagging.append('-')\n",
    "        # 음절 띄어쓰기\n",
    "        syllables.append(' ')\n",
    "        # 음절 띄어쓰기 태깅\n",
    "        syllables_tagging.append('-')\n",
    "    \n",
    "    # ------------------------------------------------------------------------------------------------------------ #\n",
    "    # name 2\n",
    "    # 어절\n",
    "    for i in range(0, len(name2_words)) :\n",
    "        words.append(name2_words[i])\n",
    "    # 태그된 어절\n",
    "    for i in range(0, len(name2_words_tagging)) :\n",
    "        words_tagging.append(name2_words_tagging[i])\n",
    "    \n",
    "    # 음절\n",
    "    for i in range(0, len(name2_syllables)) :\n",
    "        syllables.append(name2_syllables[i])\n",
    "    # 태그된 음절\n",
    "    for i in range(0, len(name2_syllables_tagging)) :\n",
    "        syllables_tagging.append(name2_syllables_tagging[i])\n",
    "        \n",
    "    # ------------------------------------------------------------------------------------------------------------ #\n",
    "    \n",
    "    # case에 맞게 \n",
    "    new_plural = ''\n",
    "    for j in range(0, len(words)) :\n",
    "        new_plural = new_plural + words[j]\n",
    "    \n",
    "    \n",
    "    return new_plural, words, words_tagging, syllables, syllables_tagging\n",
    "\n",
    "\n",
    "data = pd.read_csv('C:/Users/na2na/capstone/only_product_name.csv')\n",
    "length = data.shape[0]\n",
    "\n",
    "# 태깅 작업\n",
    "with open('C:/Users/na2na/capstone/only_product_name_tagging.csv', 'w', encoding = 'UTF-8') as file :\n",
    "    wtr = csv.writer(file, delimiter = ',')   \n",
    "    wtr.writerow(['product', 'words', 'words_tagging', 'syllables', 'syllables_tagging'])\n",
    "\n",
    "    for line in range(0, length) :\n",
    "        product = data.loc[line, 'product']\n",
    "        words, words_tagging = tagging_words(product)\n",
    "        syllables, syl_tagging = tagging_syllables(product, words, words_tagging)\n",
    "        wtr.writerow([product, words, words_tagging, syllables, syl_tagging])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 태깅된 csv에 복수 추가-----------------------------------------------------------------------------------\n",
    "# 데이터 길이 갱신\n",
    "# data = pd.read_csv('C:/Users/na2na/capstone/prod_tagging_.csv')\n",
    "# length = data.shape[0]\n",
    "# # 태깅이 올바르게 된 것을 가지고 돌려야 함. csv파일의 태깅된 것을 활용하기 때문\n",
    "# with open('C:/Users/na2na/capstone/prod_tagging_.csv', 'a', encoding = 'UTF-8') as file :\n",
    "#     wtr = csv.writer(file, delimiter = ',')\n",
    "    \n",
    "#     # 복수 상품 생성은 원하는 만큼.\n",
    "#     for i in range(0, 1619) :\n",
    "#         product, words, words_tagging, syllables, syllables_tagging = choose_plural('C:/Users/na2na/capstone/prod_tagging_.csv', length)\n",
    "#         wtr.writerow([product, words, words_tagging, syllables, syllables_tagging])\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "# 문장 어절 태깅 -> 음절태깅\n",
    "# data = pd.read_csv('C:/Users/na2na/capstone/only_product_name.csv')\n",
    "# length = data.shape[0]\n",
    "\n",
    "# with open('C:/Users/na2na/capstone/only_product_name_tagging.csv', 'a', encoding = 'UTF-8') as file :\n",
    "#     wtr = csv.writer(file, delimiter = ',')\n",
    "#     syl = []\n",
    "#     syl_tag = []\n",
    "#     for line in range(0, length) :\n",
    "#         print(line)\n",
    "#         product = data.loc[line, 'sentence']\n",
    "#         words = str_to_list(data.loc[line, 'words'])\n",
    "#         words_tagging = str_to_list(data.loc[line, 'words_tag'])\n",
    "#         syllables, syl_tagging = tagging_syllables(product, words, words_tagging)\n",
    "#         syl.append(syllables)\n",
    "#         syl_tag.append(syl_tagging)\n",
    "#     data['syllables'] = syl\n",
    "#     data['syllables_tag'] = syl_tag\n",
    "\n",
    "# data.to_csv('C:/Users/na2na/capstone/only_product_name_tagging.csv')\n",
    "\n",
    "# test\n",
    "# sentence = '이거네 소갈비살 스테이크 팔아'\n",
    "# words_tagging = \"['PRD_B', ' PRD_I', ' PRD_I', ' PRD_I', ' PRD_I', '-', '-']\"\n",
    "# str_to_list(words_tagging)\n",
    "\n",
    "\n",
    "# syllables, syl_tagging = tagging_syllables(sentence, words, words_tagging)\n",
    "# print(syllables)\n",
    "# print(syl_tagging)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.read_csv('C:/Users/na2na/capstone/random_prod_tagging2.csv')\n",
    "csvdt = dt.to_csv('C:/Users/na2na/capstone/random_prod_tagging2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Unnamed: 0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\na2na\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2656\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2657\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Unnamed: 0'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-21deb529e8d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mdel\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Unnamed: 0'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/na2na/capstone/sentence_tag_real_final.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\na2na\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__delitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3313\u001b[0m             \u001b[1;31m# there was no match, this call should raise the appropriate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3314\u001b[0m             \u001b[1;31m# exception:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3315\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3317\u001b[0m         \u001b[1;31m# delete from the caches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\na2na\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mdelete\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    983\u001b[0m         \u001b[0mDelete\u001b[0m \u001b[0mselected\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mitems\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnon\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mplace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \"\"\"\n\u001b[1;32m--> 985\u001b[1;33m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[0mis_deleted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\na2na\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2657\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2659\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Unnamed: 0'"
     ]
    }
   ],
   "source": [
    "del data['Unnamed: 0']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('C:/Users/na2na/capstone/sentence_tag_real_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
